# Module 7 - The AI Watcher

> Running AI in production without observability is like teaching a class in the dark with a blindfold on - you have no idea if students are learning, confused, or have already left the room. Let's give Canopy the vital signs and instrumentation it needs to stay healthy and trustworthy üìä

# üßë‚Äçüç≥ Module Intro

You've built Canopy with RAG capabilities and safety guardrails, but how do you know it's actually working well in production? This module introduces the three pillars of observability that transform your AI application from a black box into a transparent, monitorable system you can trust.

You'll learn to use OpenShift AI's built-in observability stack: metrics to quantify performance, logs to understand behavior, and traces to follow requests through your distributed system. By the end, you'll have dashboards that show Canopy's health at a glance and the skills to debug issues quickly.

# üñºÔ∏è Big Picture
![big-picture-observability](images/big-picture-monitoring.jpg)

# üîÆ Learning Outcomes

* Understand the three pillars of observability and why they're essential for production AI systems
* Deploy and configure OpenShift AI's observability stack with OpenTelemetry, Prometheus, and Tempo
* Query metrics using PromQL to monitor Canopy's performance and resource usage
* Create custom Grafana dashboards to visualize AI-specific metrics and system health
* Analyze logs using OpenShift's logging stack to debug issues and understand user interactions
* Trace requests through distributed components to identify bottlenecks and latency sources

# üî® Tools used in this module

* **OpenTelemetry Collector (OTel)**: Vendor-neutral standard for collecting telemetry data from your AI workloads
* **Prometheus**: Time-series database that stores metrics and powers alerting
* **Grafana**: Visualization platform that turns metrics into actionable dashboards
* **Red Hat build of Tempo**: Distributed tracing system that follows requests across microservices
* **LokiStack**: Scalable log aggregation system integrated with OpenShift
* **OpenShift User Workload Monitoring**: Pre-configured monitoring stack for tracking custom application metrics and model performance
