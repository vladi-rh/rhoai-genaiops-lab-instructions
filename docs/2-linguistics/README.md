# Module 2 - Linguistics

> Learn the art of communicating with AI through prompt engineering.

# ğŸ§‘â€ğŸ³ Module Intro

This module bridges the gap between raw LLM capabilities and practical applications.

# ğŸ–¼ï¸ Big Picture
_an image will be inserted here._

# ğŸ”® Learning Outcomes

* Understand how system and user prompts shape LLM behavior and responses
* Learn prompt engineering techniques for educational use cases
* Explore version-controlled prompt templates using Git as a registry
* Practice deploying and configuring Canopy AI with custom prompts

# ğŸ”¨ Tools used in this module

* Prompt Playground - Interactive Gradio interface for experimenting with prompt engineering
* Git-based Prompt Registry - Version-controlled system for managing and deploying prompt templates
* OpenShift Deployment Tools - Platform tools for configuring and running Canopy AI instances

