# Module 2 - Linguistics

> Prompting an AI is like giving instructions to a chef. If you just say â€˜make food,â€™ youâ€™ll get whatever. If you say â€˜make a vegetarian pasta in under 15 minutes,â€™ youâ€™re far more likely to get what you want ğŸ

# ğŸ§‘â€ğŸ³ Module Intro

This module bridges the gap between raw LLM capabilities and practical applications.

# ğŸ–¼ï¸ Big Picture
_an image will be inserted here._

# ğŸ”® Learning Outcomes

* Understand how system and user prompts shape LLM behavior and responses
* Learn prompt engineering techniques for educational use cases
* Practice deploying and configuring Canopy AI with custom prompts

# ğŸ”¨ Tools used in this module

* Prompt Playground - Interactive Gradio interface for experimenting with prompt engineering
* OpenShift & Helm Charts - To deploy Canopy UI in a development environment

